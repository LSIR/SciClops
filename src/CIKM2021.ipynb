{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import random\n",
    "\n",
    "sciclops_dir = str(Path.home()) + '/data/sciclops/' \n",
    "hn_vocabulary = set(map(str.lower, open(sciclops_dir + 'etc/hn_vocabulary/hn_vocabulary.txt').read().splitlines()))\n",
    "health = set(map(str.lower, open(sciclops_dir + 'etc/hn_vocabulary/health.txt').read().splitlines()))\n",
    "\n",
    "random.seed(42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RMSEs of Experts, Non-Experts, Commercial Systems"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_claimbuster = pd.read_csv(sciclops_dir+'evaluation/claimbuster.csv').rename(columns={'Scientific Claim': 'claim', 'fact_check': 'validity'}).drop('URL', axis=1)\n",
    "df_google = pd.read_csv(sciclops_dir+'evaluation/google.csv').rename(columns={'Scientific Claim': 'claim', 'fact_check': 'validity'}).drop('URL', axis=1).fillna(random.randint(-2, 2))\n",
    "\n",
    "df_enhanced = pd.read_csv(sciclops_dir+'evaluation/enhanced_context.csv')\n",
    "df_enhanced['claim'] = df_enhanced['Input.main_claim']\n",
    "df_enhanced ['validity'] = 0 * df_enhanced['Answer.ValidityNA.ValidityNA'] + (-2) * df_enhanced['Answer.Validity-2.Validity-2'] + (-1) * df_enhanced['Answer.Validity-1.Validity-1'] + 0 * df_enhanced['Answer.Validity0.Validity0'] + 1 * df_enhanced['Answer.Validity+1.Validity+1'] + 2 * df_enhanced['Answer.Validity+2.Validity+2']\n",
    "df_enhanced = df_enhanced[['claim', 'validity']]\n",
    "df_enhanced = df_enhanced.groupby('claim').mean().reset_index()\n",
    "\n",
    "df_original = pd.read_csv(sciclops_dir+'evaluation/original_context.csv')\n",
    "df_original['claim'] = df_original['Input.main_claim']\n",
    "df_original ['validity'] = 0 * df_original['Answer.ValidityNA.ValidityNA'] + (-2) * df_original['Answer.Validity-2.Validity-2'] + (-1) * df_original['Answer.Validity-1.Validity-1'] + 0 * df_original['Answer.Validity0.Validity0'] + 1 * df_original['Answer.Validity+1.Validity+1'] + 2 * df_original['Answer.Validity+2.Validity+2']\n",
    "df_original = df_original[['claim', 'validity']]\n",
    "df_original = df_original.groupby('claim').mean().reset_index()\n",
    "\n",
    "df_no = pd.read_csv(sciclops_dir+'evaluation/no_context.csv')\n",
    "df_no['claim'] = df_no['Input.main_claim']\n",
    "df_no ['validity'] = 0 * df_no['Answer.ValidityNA.ValidityNA'] + (-2) * df_no['Answer.Validity-2.Validity-2'] + (-1) * df_no['Answer.Validity-1.Validity-1'] + 0 * df_no['Answer.Validity0.Validity0'] + 1 * df_no['Answer.Validity+1.Validity+1'] + 2 * df_no['Answer.Validity+2.Validity+2']\n",
    "df_no = df_no[['claim', 'validity']]\n",
    "df_no = df_no.groupby('claim').mean().reset_index()\n",
    "\n",
    "df_sylvia = pd.read_csv(sciclops_dir+'evaluation/expert_1.csv')\n",
    "df_sylvia['claim'] = df_sylvia['Scientific Claim']\n",
    "df_sylvia['validity'] = df_sylvia['Validity [-2,+2]']\n",
    "df_sylvia = df_sylvia[['claim', 'validity']]\n",
    "\n",
    "df_dimitra = pd.read_csv(sciclops_dir+'evaluation/expert_2.csv')\n",
    "df_dimitra['claim'] = df_dimitra['Scientific Claim']\n",
    "df_dimitra['validity'] = df_dimitra['Validity [-2,+2]']\n",
    "df_dimitra = df_dimitra[['claim', 'validity']]\n",
    "\n",
    "df_experts = df_dimitra.merge(df_sylvia, on='claim')\n",
    "df_experts.validity_x = df_experts.validity_x.fillna(df_experts.validity_y)\n",
    "print(mean_squared_error(df_experts.validity_x, df_experts.validity_y, squared=False))\n",
    "df_experts['validity'] = df_experts[['validity_x', 'validity_y']].mean(axis=1)\n",
    "df_experts = df_experts[['claim', 'validity']]\n",
    "\n",
    "df = df_experts.merge(df_no, on='claim')\n",
    "print(mean_squared_error(df.validity_x, df.validity_y, squared=False))\n",
    "\n",
    "df = df_experts.merge(df_original, on='claim')\n",
    "print(mean_squared_error(df.validity_x, df.validity_y, squared=False))\n",
    "\n",
    "df = df_experts.merge(df_enhanced, on='claim')\n",
    "print(mean_squared_error(df.validity_x, df.validity_y, squared=False))\n",
    "\n",
    "df = df_experts.merge(df_claimbuster, on='claim')\n",
    "print(mean_squared_error(df.validity_x, df.validity_y, squared=False))\n",
    "\n",
    "df = df_experts.merge(df_google, on='claim')\n",
    "print(mean_squared_error(df.validity_x, df.validity_y, squared=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Work time of Non-Experts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(pd.read_csv(sciclops_dir+'evaluation/enhanced_context.csv').WorkTimeInSeconds.median())\n",
    "print(pd.read_csv(sciclops_dir+'evaluation/original_context.csv').WorkTimeInSeconds.median())\n",
    "print(pd.read_csv(sciclops_dir+'evaluation/no_context.csv').WorkTimeInSeconds.median())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Confidence and Effort KDEs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_enhanced = pd.read_csv(sciclops_dir+'evaluation/enhanced_context.csv')\n",
    "df_enhanced['claim'] = df_enhanced['Input.main_claim']\n",
    "df_enhanced['confidence'] = 1 * df_enhanced['Answer.Confidence1.Confidence1'] + 2 * df_enhanced['Answer.Confidence2.Confidence2'] + 3 * df_enhanced['Answer.Confidence3.Confidence3'] + 4 * df_enhanced['Answer.Confidence4.Confidence4'] + 5 * df_enhanced['Answer.Confidence5.Confidence5']\n",
    "df_enhanced['effort'] = 0 * df_enhanced['Answer.Effort0.Effort0'] + 1 * df_enhanced['Answer.Effort1.Effort1'] + 2 * df_enhanced['Answer.Effort2.Effort2'] + 3 * df_enhanced['Answer.Effort3.Effort3'] + 4 * df_enhanced['Answer.Effort4.Effort4'] + 5 * df_enhanced['Answer.Effort5.Effort5']\n",
    "df_enhanced ['validity'] = 0 * df_enhanced['Answer.ValidityNA.ValidityNA'] + (-2) * df_enhanced['Answer.Validity-2.Validity-2'] + (-1) * df_enhanced['Answer.Validity-1.Validity-1'] + 0 * df_enhanced['Answer.Validity0.Validity0'] + 1 * df_enhanced['Answer.Validity+1.Validity+1'] + 2 * df_enhanced['Answer.Validity+2.Validity+2']\n",
    "df_enhanced = df_enhanced[['claim', 'confidence', 'effort', 'validity']]\n",
    "\n",
    "df_original = pd.read_csv(sciclops_dir+'evaluation/original_context.csv')\n",
    "df_original['claim'] = df_original['Input.main_claim']\n",
    "df_original['confidence'] = 1 * df_original['Answer.Confidence1.Confidence1'] + 2 * df_original['Answer.Confidence2.Confidence2']+ 3 * df_original['Answer.Confidence3.Confidence3']\n",
    "df_original['effort'] = 0 * df_original['Answer.Effort0.Effort0'] + 1 * df_original['Answer.Effort1.Effort1'] + 2 * df_original['Answer.Effort2.Effort2'] + 3 * df_original['Answer.Effort3.Effort3'] \n",
    "df_original ['validity'] = 0 * df_original['Answer.ValidityNA.ValidityNA'] + (-2) * df_original['Answer.Validity-2.Validity-2'] + (-1) * df_original['Answer.Validity-1.Validity-1'] + 0 * df_original['Answer.Validity0.Validity0'] + 1 * df_original['Answer.Validity+1.Validity+1'] + 2 * df_original['Answer.Validity+2.Validity+2']\n",
    "df_original = df_original[['claim', 'confidence', 'effort', 'validity']]\n",
    "\n",
    "df_no = pd.read_csv(sciclops_dir+'evaluation/no_context.csv')\n",
    "df_no['claim'] = df_no['Input.main_claim']\n",
    "df_no['confidence'] = 1 * df_no['Answer.Confidence1.Confidence1'] + 2 * df_no['Answer.Confidence2.Confidence2']+ 3 * df_no['Answer.Confidence3.Confidence3']\n",
    "df_no['effort'] = 0 * df_no['Answer.Effort0.Effort0'] + 1 * df_no['Answer.Effort1.Effort1'] + 2 * df_no['Answer.Effort2.Effort2'] + 3 * df_no['Answer.Effort3.Effort3'] \n",
    "df_no ['validity'] = 0 * df_no['Answer.ValidityNA.ValidityNA'] + (-2) * df_no['Answer.Validity-2.Validity-2'] + (-1) * df_no['Answer.Validity-1.Validity-1'] + 0 * df_no['Answer.Validity0.Validity0'] + 1 * df_no['Answer.Validity+1.Validity+1'] + 2 * df_no['Answer.Validity+2.Validity+2']\n",
    "df_no = df_no[['claim', 'confidence', 'effort', 'validity']]\n",
    "\n",
    "sns.set(context='paper', style='white', color_codes=True, font_scale=2.5)\n",
    "sns.set_palette('colorblind')\n",
    "# plt.rc('pdf',fonttype = 42)\n",
    "plt.rcParams['text.usetex'] = True\n",
    "fig, (ax0, ax1) = plt.subplots(nrows=1, ncols=2, figsize=(25,10))\n",
    "for ind, ax in zip(['confidence', 'effort'], [ax0, ax1]):\n",
    "\tfor df, l, c in zip([df_no, df_original, df_enhanced], ['Without', 'With Partial', 'With Enhanced'], ['#2DA8D8FF', '#2A2B2DFF', '#D9514EFF']):\n",
    "\t\t#df = df.sort_values(by='confidence')[:int(.3*len(df))]\n",
    "\t\tax = sns.kdeplot(df.groupby('claim').mean()[ind], label=l+' Context', color=c, shade= True, ax=ax)\n",
    "\t\tax.set(ylim=(0, .9))\t\n",
    "\t\tax.set_xlabel(ind.capitalize(), fontsize='xx-large')\n",
    "\t\t# ax.get_legend().remove()\n",
    "\t\tax.set_xticks([0,2,4])\n",
    "\t\tax.set_xticklabels(['Low', 'Medium', 'High'], fontsize='x-large')\n",
    "\n",
    "ax0.set_ylabel('Density', fontsize='xx-large')\t\n",
    "ax0.tick_params(axis='y', which='major', labelsize='x-large')\n",
    "ax1.get_yaxis().set_visible(False)\n",
    "\n",
    "lines, labels = ax1.get_legend_handles_labels()    \n",
    "legend = fig.legend(lines, labels, title='Non-Experts', loc = 'upper right', ncol=1, bbox_to_anchor=(.93, .93), frameon=False, fontsize='xx-large', title_fontsize='xx-large')\n",
    "\n",
    "for handle in legend.legendHandles:\n",
    "\thandle.set_linewidth('2.0')\t\n",
    "\n",
    "sns.despine(left=True, bottom=True)\n",
    "plt.show()\n",
    "fig.savefig(sciclops_dir+'evaluation/KDEs.pdf', bbox_inches='tight')"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "d320936fe8ac3ddaddda42523c05a9197966085b5afc9614ddd53b320a89161a"
  },
  "kernelspec": {
   "display_name": "Python 3.8.12 64-bit ('base': conda)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
